# app_streamlit.py
# Streamlit å¹³å°ï¼šä¸Šä¼ CSV -> å‹¾é€‰æ¨¡å‹ -> è¿è¡Œ -> æŒ‡æ ‡&æ›²çº¿ -> å¯¼å‡ºPDF

import io
import os
from datetime import datetime

import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt

import streamlit as st

from utils import load_times, cum_to_intervals, ensure_output_dir
from metrics import mae, rmse, mspe, r2, ae, ks_test_residuals, ks_on_u_values
# å¼•å…¥åŸæœ‰æ¨¡å‹
from srgm.go import GOModel
from srgm.jm import JMModel
from srgm.mo import MOModel
from srgm.s_shaped import SShapedModel
# å¼•å…¥æ–°æ¨¡å‹ (è¯·ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®)
from time_series.gm11 import GM11
from time_series.arima_model import ArimaReliability

from ml_models.svr_model import SVRReliability
from ml_models.bpnn_model import BPNNReliability
# å¼•å…¥å¯è§†åŒ–è¾…åŠ©
from viz_srgm import (
    build_metrics_table,
    plot_cum_failures,
    compute_u_sequence,
    plot_u_y,
    compute_resid_corr,
    compute_plr_loglik,
    plot_jm_intervals,
)

# è®© matplotlib æ”¯æŒä¸­æ–‡æ˜¾ç¤º
matplotlib.rcParams["font.sans-serif"] = ["SimHei", "Microsoft YaHei", "DejaVu Sans", "WenQuanYi Zen Hei"]
matplotlib.rcParams["axes.unicode_minus"] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜

# ---------- é¡µé¢åŸºç¡€ ----------
st.set_page_config(page_title="è½¯ä»¶å¯é æ€§å¢é•¿æ¨¡å‹å¹³å°", layout="wide")
st.title("è½¯ä»¶å¯é æ€§å¢é•¿æ¨¡å‹")
st.caption("ä¸Šä¼  CSV â†’ å‹¾é€‰æ¨¡å‹ â†’ ä¸€é”®è¿è¡Œ â†’ æŒ‡æ ‡ & æ›²çº¿ â†’ å¯¼å‡º PDF æŠ¥å‘Š")


# ---------- å¸®åŠ©å‡½æ•° ----------
def load_csv_t_or_interval(file_obj: io.BytesIO | str):
    """å…è®¸ CSV æœ‰ 't'(ç´¯è®¡æ—¶åˆ») æˆ– 'interval'(é—´éš”) ä¸¤ç§æ ¼å¼ã€‚è¿”å›ç´¯è®¡æ—¶åˆ» t(np.ndarray)ã€‚"""
    df = pd.read_csv(file_obj)
    cols = [c.lower() for c in df.columns]
    df.columns = cols
    if "t" in df.columns:
        t = df["t"].to_numpy(dtype=float)
        if np.any(np.diff(t) <= 0):
            # å…è®¸ç›¸ç­‰æ—¶é—´å‘ç”Ÿå¤šæ¬¡å¤±æ•ˆï¼Œä½†ä¸å…è®¸æ—¶é—´å€’æµ
            if np.any(np.diff(t) < 0):
                raise ValueError("'t' å¿…é¡»éé€’å‡")
        return t
    elif "interval" in df.columns:
        d = df["interval"].to_numpy(dtype=float)
        if np.any(d <= 0):
            # ä¸¥æ ¼æ¥è¯´é—´éš”åº”ä¸ºæ­£ï¼Œä½†æçŸ­æ—¶é—´é—´éš”å…è®¸ä¸º0
            pass
        return np.cumsum(d)
    else:
        raise ValueError("CSV å¿…é¡»åŒ…å«åˆ— 't'ï¼ˆç´¯è®¡æ—¶åˆ»ï¼‰æˆ– 'interval'ï¼ˆé—´éš”ï¼‰")


def ess(y_true, y_pred) -> float:
    """è¯¯å·®å¹³æ–¹å’Œ ESS = sum((actual - predicted)^2)ã€‚"""
    y_true = np.asarray(y_true, dtype=float)
    y_pred = np.asarray(y_pred, dtype=float)
    return float(np.sum((y_true - y_pred) ** 2))


def fit_and_eval_on_cum(model, t_train, t_valid):
    """
    GO/MO/S (SRGM)ï¼šåœ¨ç´¯è®¡æ—¶åˆ»åŸŸåšæå¤§ä¼¼ç„¶æ‹Ÿåˆã€‚
    é¢„æµ‹ç›®æ ‡ï¼šç»™å®šæ—¶åˆ» tï¼Œé¢„æµ‹ç´¯è®¡å¤±æ•ˆæ•° m(t)ã€‚
    """
    t_all = np.concatenate([t_train, t_valid])
    model.fit(t_train)  # æ‹Ÿåˆåªç”¨è®­ç»ƒæ®µ

    # SRGM æ˜¯ç»™å‡ºæ—¶é—´ tï¼Œé¢„æµ‹å¤±æ•ˆæ•° y
    y_true_train = np.arange(1, len(t_train) + 1, dtype=float)
    y_hat_train = model.predict_cum(t_train)

    y_true_valid = np.arange(len(t_train) + 1, len(t_all) + 1, dtype=float)
    y_hat_valid = model.predict_cum(t_all)[len(t_train):]

    metrics_train = {
        "MAE": mae(y_true_train, y_hat_train),
        "AE": ae(y_true_train, y_hat_train),
        "RMSE": rmse(y_true_train, y_hat_train),
        "MSPE": mspe(y_true_train, y_hat_train),
        "R2": r2(y_true_train, y_hat_train),
        "ESS": ess(y_true_train, y_hat_train),
    }
    metrics_valid = {
        "MAE": mae(y_true_valid, y_hat_valid),
        "AE": ae(y_true_valid, y_hat_valid),
        "RMSE": rmse(y_true_valid, y_hat_valid),
        "MSPE": mspe(y_true_valid, y_hat_valid),
        "R2": r2(y_true_valid, y_hat_valid),
        "ESS": ess(y_true_valid, y_hat_valid),
        "AE_last": ae(y_true_valid[-1], y_hat_valid[-1]) if len(y_hat_valid) > 0 else 0,
    }

    ks_train = ks_test_residuals(y_true_train, y_hat_train)
    ks_valid = ks_test_residuals(y_true_valid, y_hat_valid)

    return {
        "type": "SRGM",  # æ ‡è®°ç±»å‹
        "metrics_train": metrics_train,
        "metrics_valid": metrics_valid,
        "ks_train": ks_train,
        "ks_valid": ks_valid,
        "y_true_train": y_true_train,  # ç´¯è®¡å¤±æ•ˆæ•° 1,2,3...
        "y_hat_train": y_hat_train,
        "y_true_valid": y_true_valid,
        "y_hat_valid": y_hat_valid,
        "model_obj": model  # å­˜å‚¨æ¨¡å‹å¯¹è±¡ä»¥ä¾¿åç»­ä½¿ç”¨
    }


def fit_and_eval_time_series(model_name, t_train, t_valid, arima_order=(1, 1, 1), params=None):
    """
    GM(1,1) / ARIMAï¼šæ—¶é—´åºåˆ—é¢„æµ‹ã€‚
    é¢„æµ‹ç›®æ ‡ï¼šç»™å®šå¤±æ•ˆåºå· iï¼Œé¢„æµ‹å¤±æ•ˆæ—¶é—´ t_iã€‚
    æ³¨æ„ï¼šè¿™é‡Œçš„é¢„æµ‹æ–¹å‘ä¸ SRGM ç›¸åï¼ˆSRGMæ˜¯ t->m(t)ï¼ŒTSæ˜¯ i->t_iï¼‰ã€‚
    ä¸ºäº†ç»Ÿä¸€ç”»å›¾ï¼ˆç”» m(t) æ›²çº¿ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦æŠŠé¢„æµ‹å‡ºçš„ t_i è½¬æ¢å› (t, m(t)) çš„å½¢å¼ã€‚
    """
    t_all = np.concatenate([t_train, t_valid])
    # ç¡®ä¿ params æ˜¯å­—å…¸ï¼Œé˜²æ­¢ NoneType é”™è¯¯
    if params is None:
        params = {}
    # è®­ç»ƒæ¨¡å‹ï¼šè¾“å…¥æ˜¯å¤±æ•ˆæ—¶é—´åºåˆ—
    if model_name == "GM(1,1)":
        model = GM11()
        model.fit(t_train)
        # é¢„æµ‹ï¼šå†å²æ‹Ÿåˆ + æœªæ¥é¢„æµ‹
        # predict è¿”å›çš„æ˜¯å®Œæ•´çš„åºåˆ— (len = len(t_train) + len(t_valid))
        preds_all = model.predict(n_steps=len(t_valid))

    elif model_name == "ARIMA":
        model = ArimaReliability(order=arima_order)
        model.fit(t_train)
        hist_fit, future_pred = model.predict(n_steps=len(t_valid))
        preds_all = np.concatenate([hist_fit, future_pred])
    # --- æ–°å¢ä»£ç  (SVR & BP) ---
    elif model_name == "SVR":
        # params ç»“æ„: {'window': 3, 'C': 100, 'gamma': 0.1}
        w = params.get('window', 3)
        c = params.get('C', 100)
        g = params.get('gamma', 0.1)
        model = SVRReliability(window_size=w, C=c, gamma=g)
        model.fit(t_train)
        hist_fit, future_pred = model.predict(n_steps=len(t_valid))
        preds_all = np.concatenate([hist_fit, future_pred])

    elif model_name == "BPNN":
        # params ç»“æ„: {'window': 3, 'hidden': (100,), 'iter': 2000}
        w = params.get('window', 3)
        h = params.get('hidden', (100,))
        itr = params.get('iter', 2000)
        model = BPNNReliability(window_size=w, hidden_layer_sizes=h, max_iter=itr)
        model.fit(t_train)
        hist_fit, future_pred = model.predict(n_steps=len(t_valid))
        preds_all = np.concatenate([hist_fit, future_pred])

    # --- è½¬æ¢å› m(t) è§†è§’è¿›è¡ŒæŒ‡æ ‡è®¡ç®— ---
    # æ—¶é—´åºåˆ—æ¨¡å‹ç›´æ¥é¢„æµ‹çš„æ˜¯â€œç¬¬iæ¬¡å¤±æ•ˆå‘ç”Ÿçš„æ—¶é—´â€
    # æ‰€ä»¥ y_true æ˜¯ t_train/t_valid (æ—¶é—´)
    # y_pred æ˜¯æ¨¡å‹è¾“å‡ºçš„é¢„æµ‹æ—¶é—´

    # è®­ç»ƒéƒ¨åˆ†
    pred_t_train = preds_all[:len(t_train)]
    # éªŒè¯éƒ¨åˆ†
    pred_t_valid = preds_all[len(t_train):]

    # ä¸ºäº†èƒ½åœ¨â€œæŒ‡æ ‡æ€»è§ˆâ€é‡Œå’Œ SRGM æ¯”è¾ƒï¼Œæˆ‘ä»¬é€šå¸¸æ¯”è¾ƒâ€œæ—¶é—´è¯¯å·®â€æˆ–è€…â€œå¤±æ•ˆæ•°è¯¯å·®â€ã€‚
    # SRGM è®¡ç®—çš„æ˜¯å¤±æ•ˆæ•°è¯¯å·® (é¢„æµ‹ m(t) vs çœŸå® i)ã€‚
    # TS æ¨¡å‹è®¡ç®—çš„æ˜¯æ—¶é—´è¯¯å·® (é¢„æµ‹ t_i vs çœŸå® t)ã€‚
    # è¿™é‡Œä¸ºäº†å±•ç¤º TS æ¨¡å‹çš„åŸç”Ÿæ€§èƒ½ï¼Œæˆ‘ä»¬è®¡ç®— **æ—¶é—´è¯¯å·®**ã€‚
    # å¹¶åœ¨è¡¨æ ¼å¤‡æ³¨ä¸­è¯´æ˜ã€‚

    metrics_train = {
        "MAE": mae(t_train, pred_t_train),
        "RMSE": rmse(t_train, pred_t_train),
        "MSPE": mspe(t_train, pred_t_train),  # æ—¶é—´çš„ç™¾åˆ†æ¯”è¯¯å·®
        "R2": r2(t_train, pred_t_train),
        "ESS": ess(t_train, pred_t_train),
        "AE": ae(t_train, pred_t_train)
    }

    metrics_valid = {
        "MAE": mae(t_valid, pred_t_valid),
        "RMSE": rmse(t_valid, pred_t_valid),
        "MSPE": mspe(t_valid, pred_t_valid),
        "R2": r2(t_valid, pred_t_valid),
        "ESS": ess(t_valid, pred_t_valid),
        "AE_last": ae(t_valid[-1], pred_t_valid[-1]) if len(t_valid) > 0 else 0
    }

    return {
        "type": "TimeSeries",
        "metrics_train": metrics_train,
        "metrics_valid": metrics_valid,
        # ç”¨äºç”»å›¾çš„æ•°æ®ï¼š
        # xè½´æ˜¯ æ—¶é—´(é¢„æµ‹å€¼), yè½´æ˜¯ å¤±æ•ˆåºå·(1,2,3...)
        "pred_t_all": preds_all,
        "t_train_true": t_train,
        "t_valid_true": t_valid
    }


def eval_jm_on_intervals(t_train, t_valid):
    """
    JMï¼šåœ¨â€œé—´éš”åŸŸâ€åšè¯„ä¼°ã€‚
    """
    d_train = cum_to_intervals(t_train)
    d_valid = cum_to_intervals(np.concatenate([t_train, t_valid]))[len(d_train):]

    jm = JMModel().fit(d_train)

    k_train = np.arange(1, len(d_train) + 1, dtype=float)
    k_valid = np.arange(len(d_train) + 1, len(d_train) + len(d_valid) + 1, dtype=float)

    # æœŸæœ›é—´éš”
    yhat_train = np.array([jm.expected_interval(int(k)) for k in k_train], dtype=float)
    yhat_valid = np.array([jm.expected_interval(int(k)) for k in k_valid], dtype=float)

    # æŒ‡æ ‡ï¼ˆé—´éš”åŸŸï¼‰
    mtrain = {
        "MAE": mae(d_train, yhat_train),
        "AE": ae(d_train, yhat_train),
        "RMSE": rmse(d_train, yhat_train),
        "MSPE": mspe(d_train, yhat_train),
        "R2": r2(d_train, yhat_train),
        "ESS": ess(d_train, yhat_train),
    }
    mvalid = {
        "MAE": mae(d_valid, yhat_valid),
        "AE": ae(d_valid, yhat_valid),
        "RMSE": rmse(d_valid, yhat_valid),
        "MSPE": mspe(d_valid, yhat_valid),
        "R2": r2(d_valid, yhat_valid),
        "ESS": ess(d_valid, yhat_valid),
        "AE_last": ae(d_valid[-1], yhat_valid[-1]) if len(d_valid) > 0 else np.nan,
    }

    return {
        "type": "JM",
        "metrics_train": mtrain,
        "metrics_valid": mvalid,
        "k_train": k_train,
        "d_train": d_train,
        "yhat_train": yhat_train,
        "k_valid": k_valid,
        "d_valid": d_valid,
        "yhat_valid": yhat_valid,
    }


def fig_to_bytes(fig) -> bytes:
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=150, bbox_inches="tight")
    plt.close(fig)
    buf.seek(0)
    return buf.getvalue()


def make_pdf_bytes(title: str, metrics_df: pd.DataFrame, images: list[bytes], meta_text: str) -> bytes:
    """ç”¨ reportlab ç”Ÿæˆ PDF å¹¶è¿”å›å­—èŠ‚æµã€‚"""
    from reportlab.lib.pagesizes import A4
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle
    from reportlab.lib.styles import getSampleStyleSheet
    from reportlab.lib import colors

    buf = io.BytesIO()
    doc = SimpleDocTemplate(buf, pagesize=A4)
    styles = getSampleStyleSheet()
    elems = []

    # æ”¯æŒä¸­æ–‡çš„å­—ä½“è®¾ç½®ï¼ˆReportLab é»˜è®¤ä¸æ”¯æŒä¸­æ–‡ï¼Œè¿™é‡Œåšç®€å•å›é€€å¤„ç†ï¼‰
    # å¦‚æœç”Ÿäº§ç¯å¢ƒéœ€è¦ä¸­æ–‡PDFï¼Œéœ€è¦æ³¨å†Œä¸­æ–‡å­—ä½“ã€‚è¿™é‡Œç®€åŒ–ä¸ºè‹±æ–‡æ ‡é¢˜æˆ–æç¤ºã€‚
    elems.append(Paragraph(title, styles["Title"]))
    elems.append(Paragraph(meta_text, styles["Normal"]))
    elems.append(Spacer(1, 8))

    # æŒ‡æ ‡è¡¨
    # å°† DataFrame è½¬ä¸ºåˆ—è¡¨
    data = [metrics_df.columns.tolist()] + metrics_df.round(4).astype(str).values.tolist()

    # è‡ªåŠ¨è®¡ç®—åˆ—å®½ï¼ˆç®€å•ç­–ç•¥ï¼‰
    col_widths = [80] + [50] * (len(metrics_df.columns) - 1)

    tbl = Table(data, repeatRows=1, colWidths=col_widths)
    tbl.setStyle(TableStyle([
        ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
        ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),
        ("ALIGN", (1, 1), (-1, -1), "RIGHT"),
        ("FONTSIZE", (0, 0), (-1, -1), 8),
        ("BOTTOMPADDING", (0, 0), (-1, 0), 6),
    ]))
    elems.append(tbl)
    elems.append(Spacer(1, 12))

    # å›¾ç‰‡
    for img_bytes in images:
        w = 460  # px
        h = 300
        elems.append(Image(io.BytesIO(img_bytes), width=w, height=h))
        elems.append(Spacer(1, 12))

    doc.build(elems)
    pdf = buf.getvalue()
    buf.close()
    return pdf


# ---------- ä¾§è¾¹æ ï¼šå‚æ•° ----------
st.sidebar.header("å‚æ•°è®¾ç½®")
uploaded = st.sidebar.file_uploader("ä¸Šä¼  CSVï¼ˆå«åˆ— 't' æˆ– 'interval'ï¼‰", type=["csv"])
use_sample = st.sidebar.checkbox("ä½¿ç”¨ç¤ºä¾‹ data/ntds_sample.csv", value=True)

# æ¨¡å‹é€‰æ‹©
st.sidebar.subheader("é€‰æ‹©æ¨¡å‹")
selected_models = st.sidebar.multiselect(
    "SRGM æ¨¡å‹", ["GO", "JM", "MO", "S"], default=["GO", "JM"]
)
selected_ts_models = st.sidebar.multiselect(
    "æ—¶é—´åºåˆ—/æ™ºèƒ½æ¨¡å‹", ["GM(1,1)", "ARIMA", "SVR", "BPNN"], default=["GM(1,1)"]
)

# ARIMA å‚æ•° (ä»…å½“é€‰æ‹©äº†ARIMAæ—¶æ˜¾ç¤º)
if "ARIMA" in selected_ts_models:
    st.sidebar.caption("ARIMA å‚æ•° (p,d,q)")
    c1, c2, c3 = st.sidebar.columns(3)
    p_val = c1.number_input("p", 0, 5, 1)
    d_val = c2.number_input("d", 0, 2, 1)  # ç´¯ç§¯æ—¶é—´éå¹³ç¨³ï¼Œd>=1
    q_val = c3.number_input("q", 0, 5, 1)
    arima_order = (p_val, d_val, q_val)
else:
    arima_order = (1, 1, 1)

# SVR å‚æ•° (æ–°å¢)
svr_params = {}
if "SVR" in selected_ts_models:
    with st.sidebar.expander("SVR å‚æ•° (æ™ºèƒ½ç®—æ³•)"):
        svr_win = st.slider("æ»‘åŠ¨çª—å£ (Look-back)", 2, 10, 3, key="svr_w")
        svr_c = st.number_input("C (æ­£åˆ™åŒ–)", 1.0, 1000.0, 100.0, step=10.0, key="svr_c")
        svr_g = st.number_input("Gamma", 0.001, 1.0, 0.1, step=0.01, key="svr_g")
        svr_params = {'window': svr_win, 'C': svr_c, 'gamma': svr_g}

# BPNN å‚æ•° (æ–°å¢)
bp_params = {}
if "BPNN" in selected_ts_models:
    with st.sidebar.expander("BP ç¥ç»ç½‘ç»œå‚æ•°"):
        bp_win = st.slider("æ»‘åŠ¨çª—å£", 2, 10, 3, key="bp_w")
        bp_node = st.number_input("éšè—å±‚èŠ‚ç‚¹æ•°", 10, 500, 100, step=10, key="bp_n")
        bp_iter = st.number_input("æœ€å¤§è¿­ä»£æ¬¡æ•°", 500, 5000, 2000, step=100, key="bp_i")
        bp_params = {'window': bp_win, 'hidden': (bp_node,), 'iter': bp_iter}


train_ratio = st.sidebar.slider("è®­ç»ƒé›†æ¯”ä¾‹", min_value=0.5, max_value=0.95, value=0.82, step=0.01)
run_btn = st.sidebar.button("è¿è¡Œåˆ†æ", type="primary")

# ---------- ä¸»ä½“ï¼šæ•°æ®åŠ è½½ ----------
t = None
source_name = None

try:
    if uploaded is not None:
        t = load_csv_t_or_interval(uploaded)
        source_name = uploaded.name
    elif use_sample and os.path.exists("data/ntds_sample.csv"):
        t = load_csv_t_or_interval("data/ntds_sample.csv")
        source_name = "data/ntds_sample.csv"
    elif os.path.exists("data/ntds_from_slide.csv"):
        t = load_csv_t_or_interval("data/ntds_from_slide.csv")
        source_name = "data/ntds_from_slide.csv"
except Exception as e:
    st.error(f"è¯»å– CSV å‡ºé”™ï¼š{e}")

if t is None:
    st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼  CSVï¼ˆåŒ…å«åˆ— 't' æˆ– 'interval'ï¼‰ï¼Œæˆ–å‹¾é€‰ä½¿ç”¨é¡¹ç›®è‡ªå¸¦ç¤ºä¾‹ã€‚")
    st.stop()

N = len(t)
st.write(f"**æ•°æ®æ¦‚è§ˆï¼š** æ€»æ•°æ®ç‚¹æ•° N = {N}ï¼Œæ¥æºï¼š{source_name}")
split = int(max(5, min(N - 1, round(N * train_ratio))))
t_train, t_valid = t[:split], t[split:]
st.write(f"è®­ç»ƒé›†ï¼š{len(t_train)} ä¸ªç‚¹ (å‰ {train_ratio * 100:.0f}%) | éªŒè¯é›†ï¼š{len(t_valid)} ä¸ªç‚¹")

# ---------- è¿è¡Œ / ç»“æœç¼“å­˜ ----------
if run_btn:
    results: dict[str, dict] = {}

    # 1. è¿è¡Œ SRGM æ¨¡å‹
    if "GO" in selected_models:
        results["GO"] = fit_and_eval_on_cum(GOModel(), t_train, t_valid)
    if "MO" in selected_models:
        results["MO"] = fit_and_eval_on_cum(MOModel(), t_train, t_valid)
    if "S" in selected_models:
        results["S"] = fit_and_eval_on_cum(SShapedModel(), t_train, t_valid)
    if "JM" in selected_models:
        results["JM"] = eval_jm_on_intervals(t_train, t_valid)
    if "SVR" in selected_ts_models:
        results["SVR"] = fit_and_eval_time_series("SVR", t_train, t_valid, params=svr_params)

    if "BPNN" in selected_ts_models:
        results["BPNN"] = fit_and_eval_time_series("BPNN", t_train, t_valid, params=bp_params)

    # 2. è¿è¡Œ æ—¶é—´åºåˆ— æ¨¡å‹
    if "GM(1,1)" in selected_ts_models:
        results["GM(1,1)"] = fit_and_eval_time_series("GM(1,1)", t_train, t_valid)
    if "ARIMA" in selected_ts_models:
        results["ARIMA"] = fit_and_eval_time_series("ARIMA", t_train, t_valid, arima_order)

    if not results:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ã€‚")
        st.stop()

    # å­˜å…¥ session
    st.session_state["results"] = results
    st.session_state["t_train"] = t_train
    st.session_state["t_valid"] = t_valid
    st.session_state["source_name"] = source_name

# æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœ
if "results" not in st.session_state:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©æ¨¡å‹ï¼Œç„¶åç‚¹å‡» **è¿è¡Œåˆ†æ**ã€‚")
    st.stop()

# å–å‡ºç»“æœ
results = st.session_state["results"]
t_train = st.session_state["t_train"]
t_valid = st.session_state["t_valid"]
source_name = st.session_state["source_name"]

t_all = np.concatenate([t_train, t_valid])
n_all = len(t_all)
img_bytes_to_export: list[bytes] = []

# ---------- å±•ç¤ºåŒºåŸŸ ----------
st.divider()
tab_metrics, tab_curve, tab_diag, tab_jm = st.tabs(
    ["ğŸ“Š æŒ‡æ ‡æ€»è§ˆ", "ğŸ“ˆ ç´¯è®¡å¤±æ•ˆæ›²çº¿ m(t)", "ğŸ” è¯Šæ–­å·¥å…·(SRGM)", "â± JM & TS æ‹Ÿåˆ"]
)

# è®¡ç®—æŒ‡æ ‡è¡¨
metric_df = build_metrics_table(results)

# ------------ â‘  æŒ‡æ ‡æ€»è§ˆ ------------
with tab_metrics:
    st.markdown("### æ¨¡å‹æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”")
    st.markdown("""
    > **æ³¨æ„æŒ‡æ ‡çš„ç‰©ç†æ„ä¹‰ä¸åŒï¼š**
    > * **SRGM (GO, MO, S)**: é¢„æµ‹ç›®æ ‡æ˜¯ **å¤±æ•ˆæ•°**ã€‚æŒ‡æ ‡åæ˜ é¢„æµ‹å¤±æ•ˆæ•°çš„å‡†ç¡®åº¦ã€‚
    > * **TS (GM(1,1), ARIMA)**: é¢„æµ‹ç›®æ ‡æ˜¯ **æ—¶é—´**ã€‚æŒ‡æ ‡åæ˜ é¢„æµ‹å¤±æ•ˆæ—¶é—´çš„å‡†ç¡®åº¦ã€‚
    > * **JM**: é¢„æµ‹ç›®æ ‡æ˜¯ **é—´éš”**ã€‚
    """)
    st.dataframe(metric_df.style.highlight_min(axis=0, color='#d1e7dd'), use_container_width=True)

# ------------ â‘¡ æ‹Ÿåˆæ›²çº¿ m(t) ------------
with tab_curve:
    st.markdown("### ç´¯è®¡å¤±æ•ˆé¢„æµ‹æ›²çº¿ m(t)")
    st.caption("æ¨ªè½´ï¼šæ—¶é—´ tï¼Œçºµè½´ï¼šç´¯è®¡å¤±æ•ˆæ•° m(t)ã€‚SRGM ç›´æ¥è¾“å‡ºæ›²çº¿ï¼›TS æ¨¡å‹(GM/ARIMA)é€šè¿‡é¢„æµ‹çš„æ—¶é—´ç‚¹åæ¨æ›²çº¿ã€‚")

    # æˆ‘ä»¬éœ€è¦è‡ªå®šä¹‰ä¸€ä¸ªç»˜å›¾å‡½æ•°æ¥åŒæ—¶æ”¯æŒ SRGM å’Œ TS æ¨¡å‹çš„ç»˜åˆ¶
    fig_cum, ax = plt.subplots(figsize=(10, 6))

    # 1. ç”»çœŸå®æ•°æ®
    # çœŸå®æ•°æ®ç‚¹ (t, m(t)) -> (t_all[i], i+1)
    ax.step(t_all, np.arange(1, n_all + 1), where='post', label="Observed (çœŸå®æ•°æ®)", color='black', linewidth=1.5)

    # 2. ç”»åˆ†å‰²çº¿
    ax.axvline(x=t_train[-1], color='green', linestyle=':', label='Train/Test Split')

    # 3. éå†æ‰€æœ‰æ¨¡å‹ç»“æœå¹¶ç»˜åˆ¶
    colors_cycle = ['r', 'b', 'g', 'c', 'm', 'y', 'orange', 'purple']
    c_idx = 0

    for name, res in results.items():
        color = colors_cycle[c_idx % len(colors_cycle)]
        c_idx += 1

        if res["type"] == "SRGM":
            # SRGM ç»“æœ: x=t_all, y=predict_cum(t_all)
            # ä¸ºäº†å¹³æ»‘ï¼Œç”Ÿæˆæ›´å¤šç‚¹
            t_plot = np.linspace(0, t_all[-1] * 1.1, 200)
            model = res["model_obj"]
            y_plot = model.predict_cum(t_plot)
            ax.plot(t_plot, y_plot, linestyle='--', label=f"{name} (SRGM)", color=color)

        elif res["type"] == "TimeSeries":
            # TS ç»“æœ: res["pred_t_all"] æ˜¯é¢„æµ‹çš„æ—¶é—´ç‚¹åºåˆ— t_1, t_2...
            # å¯¹åº”çš„ y æ˜¯ 1, 2, ...
            pred_times = res["pred_t_all"]
            # è¿‡æ»¤æ‰éç‰©ç†æ„ä¹‰çš„æ—¶é—´ï¼ˆæ¯”å¦‚è´Ÿæ•°ï¼‰
            valid_mask = pred_times > 0
            pred_times = pred_times[valid_mask]
            pred_counts = np.arange(1, len(pred_times) + 1)

            # ç»˜åˆ¶ç‚¹å›¾æˆ–è¿çº¿
            ax.plot(pred_times, pred_counts, marker='x', linestyle='--', markersize=4,
                    label=f"{name} (Time-Series)", color=color, alpha=0.7)

        elif res["type"] == "JM":
            # JM çš„ m(t) è®¡ç®—æ¯”è¾ƒå¤æ‚ï¼ˆå®ƒæ˜¯åˆ†æ®µçš„ï¼‰ï¼Œè¿™é‡Œé€šå¸¸åœ¨ â‘£ tab å•ç‹¬çœ‹é—´éš”
            # æˆ–è€…ä½ å¯ä»¥è°ƒç”¨ model.expected_failures(t) å¦‚æœå®ç°äº†çš„è¯
            pass

    ax.set_xlabel("Time (t)")
    ax.set_ylabel("Cumulative Failures m(t)")
    ax.set_title("Reliability Growth Curves Comparison")
    ax.legend()
    ax.grid(True, alpha=0.3)

    st.pyplot(fig_cum, use_container_width=True)
    img_bytes_to_export.append(fig_to_bytes(fig_cum))

# ------------ â‘¢ é¢„æµ‹æœ‰æ•ˆæ€§è¯Šæ–­ (SRGM Only) ------------
with tab_diag:
    st.markdown("### SRGM æ¨¡å‹è¯Šæ–­ (1.2èŠ‚)")

    srgm_models = [k for k, v in results.items() if v["type"] == "SRGM"]

    if not srgm_models:
        st.info("å½“å‰æœªé€‰æ‹© SRGM ç±»æ¨¡å‹ï¼ˆGO/MO/Sï¼‰ï¼Œæ— æ³•æ˜¾ç¤ºæ­¤ç±»è¯Šæ–­å›¾ã€‚")
    else:
        model_name = st.selectbox("é€‰æ‹©è¦è¯Šæ–­çš„æ¨¡å‹ï¼š", srgm_models)
        res = results[model_name]

        # å‡†å¤‡æ•°æ®
        y_pred_all = np.concatenate([res["y_hat_train"], res["y_hat_valid"]])

        c1, c2 = st.columns(2)
        with c1:
            st.markdown("**U å›¾ (U-Plot)**")
            u_all = compute_u_sequence(res)
            if u_all is not None:
                fig_u, _ = plot_u_y(u_all, title_prefix=model_name)
                st.pyplot(fig_u, use_container_width=True)
                img_bytes_to_export.append(fig_to_bytes(fig_u))

        with c2:
            st.markdown("**PLR (åºåˆ—ä¼¼ç„¶æ¯”)**")
            loglik_cum = compute_plr_loglik(t_all, y_pred_all)
            fig_plr, ax_plr = plt.subplots(figsize=(6, 4))
            ax_plr.plot(np.arange(1, len(loglik_cum) + 1), loglik_cum)
            ax_plr.set_title(f"PLR: {model_name}")
            ax_plr.grid(True, alpha=0.3)
            st.pyplot(fig_plr, use_container_width=True)

# ------------ â‘£ JM & TS æ‹Ÿåˆç»†èŠ‚ ------------
with tab_jm:
    st.markdown("### é—´éš”åŸŸ & æ—¶é—´åŸŸ æ‹Ÿåˆè¯¦æƒ…")

    # 1. JM
    if "JM" in results:
        st.markdown("#### JM æ¨¡å‹ï¼šå¤±æ•ˆé—´éš”æ‹Ÿåˆ")
        fig_jm = plot_jm_intervals(results["JM"])
        st.pyplot(fig_jm, use_container_width=True)
        img_bytes_to_export.append(fig_to_bytes(fig_jm))

    # 2. GM(1,1) / ARIMA
    ts_results = [res for name, res in results.items() if res["type"] == "TimeSeries"]
    if ts_results:
        st.markdown("#### æ—¶é—´åºåˆ—æ¨¡å‹ï¼šå¤±æ•ˆæ—¶é—´ç‚¹é¢„æµ‹")
        for name, res in results.items():
            if res["type"] != "TimeSeries": continue

            fig_ts, ax_ts = plt.subplots(figsize=(10, 4))
            # çœŸå®æ—¶é—´ç‚¹
            indices = np.arange(1, len(t_all) + 1)
            ax_ts.plot(indices, t_all, 'k.-', label='True Time')
            # é¢„æµ‹æ—¶é—´ç‚¹
            pred_t = res["pred_t_all"]
            ax_ts.plot(indices[:len(pred_t)], pred_t, 'r--', label=f'{name} Predicted Time')

            # åˆ†å‰²çº¿
            ax_ts.axvline(x=len(t_train), color='g', linestyle=':', label='Split')

            ax_ts.set_ylabel("Failure Time (t)")
            ax_ts.set_xlabel("Failure Number (i)")
            ax_ts.set_title(f"{name} Prediction Performance")
            ax_ts.legend()
            ax_ts.grid(True, alpha=0.3)
            st.pyplot(fig_ts, use_container_width=True)
            img_bytes_to_export.append(fig_to_bytes(fig_ts))

# ---------- å¯¼å‡º PDF ----------
st.divider()
col_pdf, _ = st.columns([1, 4])
with col_pdf:
    meta = (
        f"Data: {source_name} | Train/Total: {len(t_train)}/{N} | "
        f"Date: {datetime.now().strftime('%Y-%m-%d')}"
    )
    # æ³¨æ„ï¼šå¦‚æœç¯å¢ƒä¸­æ²¡æœ‰ä¸­æ–‡å­—ä½“ï¼Œç”Ÿæˆçš„ PDF ä¸­æ–‡å¯èƒ½ä¼šä¹±ç ã€‚
    # è¿™é‡Œ title ç”¨è‹±æ–‡ä»¥ä¿å®‰å…¨ã€‚
    pdf_bytes = make_pdf_bytes(
        "Software Reliability Analysis Report", metric_df, img_bytes_to_export, meta
    )
    st.download_button(
        label="ğŸ“„ ä¸‹è½½ PDF æŠ¥å‘Š",
        data=pdf_bytes,
        file_name="SRGM_Analysis_Report.pdf",
        mime="application/pdf",
        use_container_width=True,
    )